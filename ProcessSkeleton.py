#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Oct 24 16:04:32 2017

@author: jaclynbeck

The minimum spanning tree code is based on code from 
https://github.com/jakevdp/mst_clustering , but without clustering and some
extra modifications to account for somas. 
"""

from libtiff import TIFF
import timeit
import cv2
from scipy.sparse.csgraph import minimum_spanning_tree, dijkstra, breadth_first_order
from sklearn.neighbors import kneighbors_graph
from scipy import sparse
import numpy as np
import FindSomas as fs
import pickle
import os
from Objects import DirectedNode, DirectedTree, Microglia
import Utils

"""
This function ensures that no two somas are connected by a path through the 
minimum spanning tree. Dijkstra's algorithm is used to find the shortest path
from each soma to any other point, and if there is a path between two somas,
that path is broken in the middle. 

Input: 
    tree_csr - compressed sparse matrix generated by minimum_spanning_tree
    soma_indices - list of indices into the tree array that correspond to
                   the soma centroids. 
    
Output:
    tree_csr - the modified sparse matrix tree
"""
def split_somas(tree_csr, soma_indices):
    dist, points = dijkstra(tree_csr, directed=False, 
                            indices=soma_indices, 
                            return_predecessors=True)
    
    # Using a linked-list format sparse matrix is faster for this task
    lil_tree = tree_csr.tolil()
    
    # For each soma, check if there's a path between it and another soma
    for i in range(len(soma_indices)-1):
        for j in np.arange(i+1, len(soma_indices)):
            soma1 = soma_indices[i]
            soma2 = soma_indices[j]
            
            # If a path exists, trace it and break it at the longest gap
            if dist[i,soma2] != np.inf and dist[i, soma2] > 0:
                path = []
                p = soma2
                while p != soma1:
                    distance = max(lil_tree[p, points[i,p]], lil_tree[points[i,p], p])
                    # Sanity check. It's possible to have already broken this
                    # path if, for example, 3 somas are connected in a line
                    if distance == 0:
                        path = []
                        break
                    
                    path.append((np.round_(distance, 1), p))
                    p = points[i,p] # This points us to the next node in the path
            
            
                if len(path) > 0:
                    arr = np.array(path)
                    index = np.where(arr[:,0] == arr[:,0].max())[0]
                    break_pt = sorted(index)[int(round(len(index)/2))]
            
                    # This effectively deletes the break point from the tree
                    if break_pt < len(arr)-1:
                        lil_tree[arr[break_pt,1], arr[break_pt+1,1]] = 0
                        lil_tree[arr[break_pt+1,1], arr[break_pt,1]] = 0
    
    tree_csr = lil_tree.tocsr()
    tree_csr.eliminate_zeros()
    
    return tree_csr
    
    
"""
Extracts soma centroids and contours from the information encoded in the 
skeleton image. Centroids have pixel values of 255 and body pixels have values
of 254. 

Input:
    skeleton - MxN ndarray, grayscale skeleton image
    
Output:
    somas - list of FrameSoma objects
"""
def extract_soma_information(skeleton):
    bw = skeleton.copy()
    bw[skeleton < 254] = 0  # Only get somas
    number, labels, stats, centroids = cv2.connectedComponentsWithStats(bw, connectivity=8)
    
    somas = []
    
    for i in np.arange(1, number):
        soma_coords = np.vstack(np.where(labels == i)).T
        soma = fs.FrameSoma(0, soma_coords)
        somas.append(soma)
        
    return somas


"""
Translates the sparse graph representation of the tree into directed graphs.

Input: 
    tree_csr - compressed sparse matrix generated by minimum_spanning_tree
    X - Nx3 ndarray, all (row, col, value) coordinates in the skeleton image 
    centroid_indices - indices into X of the soma centroids
    
Output:
    directedTrees - list of DirectedTree objects, one per soma
"""
def create_directed_trees(tree_csr, X, centroid_indices):
    directedTrees = []
    for c in centroid_indices:
        (inds, preds) = breadth_first_order(tree_csr, c, directed=False, 
                                            return_predecessors=True)
        nodeDict = {}
        
        centerNode = DirectedNode(c, X[c][0:2])
        dTree = DirectedTree(centerNode)
        
        node = centerNode
        nodeDict[node.value] = node
        
        for i in range(1, len(inds)):
            c_num = inds[i]
            p_num = preds[c_num]

            if p_num != node.value:
                if p_num in nodeDict.keys():
                    node = nodeDict[p_num]
                else:
                    print("Error processing node " + str(c_num) \
                          + " and predecessor " + str(p_num))
                    continue
            
            connections = len(np.where(preds == c_num)[0])
            
            # Anything that is only connected to the soma center is on the
            # soma border and needs to be thrown out
            if p_num == c and connections == 0:
                continue
            
            c_node = DirectedNode(c_num, X[c_num][0:2])
            c_node.addParent(node)
            node.children.append(c_node)
            nodeDict[c_node.value] = c_node
            
            if connections == 0:
                dTree.leaves.append(c_node)
            
        dTree.nodes = list(nodeDict.values())
        directedTrees.append(dTree)
    
    return directedTrees

   
def skeleton_to_tree(skeleton, img, somas):    
    # Make sure soma centroids are marked   
    for soma in somas:
        skeleton[soma.centroid[0], soma.centroid[1]] = 255
        
    coords = np.where((skeleton > 1)) 
    
    # Here we are adding a 3rd coordinate representing the color of the pixel,
    # so that the MST algorithm will preferentially connect brighter-colored
    # pixels together. Values are scaled between 0 and 1 and flipped so that
    # 0 = high color (high confidence that the skeleton is correct there) and 
    # 1 = low color (low confidence), so that during distance calculations
    # the high colors look closer. 
    values = skeleton[coords[0], coords[1]]-skeleton[skeleton > 1].min()
    values = 1 - values / values.max()
    #X = np.vstack((coords[0], coords[1], values)).T
    X = np.vstack(coords).T
    
    # Get a list of IDs that correspond to the soma centroids, for referencing
    # each tree's center node. 
    centroid_indices = []
    for soma in somas:
        index = np.where((X[:,0] == soma.centroid[0]) & (X[:,1] == soma.centroid[1]))[0]
        centroid_indices.append(index[0])

    # Create a nearest neighbors graph to pass to minimum_spanning_tree
    n_neighbors = 50
    G = kneighbors_graph(X, n_neighbors=n_neighbors,
                         mode='distance',
                         metric='euclidean',
                         metric_params=None)
    
    # Add the pixel values as an extra weight to the distance
    dists = np.vstack(sparse.find(G))
    pairs = np.max(values[dists[0:2].astype('int')], axis=0)
    dists[2] = dists[2] + pairs
        
    # Edit the nearest neighbors graph to artificially force the centroid and 
    # contour points to look close together. MST will connect these first
    # before looking for other points.
    lil_G = G.tolil() # Linked list format is faster for editing specific indices 
    lil_G[dists[0], dists[1]] = dists[2]
    for soma in somas:
        centroid_index = centroid_indices[somas.index(soma)]
        
        for c in soma.contour: 
            contour_index = np.where((X[:,0] == c[0]) & (X[:,1] == c[1]))[0]
            lil_G[centroid_index, contour_index] = 0.01
            lil_G[contour_index, centroid_index] = 0.01
    
    G = lil_G.tocsr()
    
    # Get the minimum spanning tree of the whole image
    tree_csr = minimum_spanning_tree(G, overwrite=True)
    
    # Break any connections that don't have adjacent pixels
    tree_csr[tree_csr > 50] = 0
    tree_csr.eliminate_zeros()
    
    # Break connections between somas
    tree_csr = split_somas(tree_csr, centroid_indices)
    
    tree_csr_img = Utils.plot_tree_csr(tree_csr, X, (1024,1024), False)
    
    directedTrees = create_directed_trees(tree_csr, X, centroid_indices)
    return directedTrees, tree_csr_img


def match_trees(videoSomas, trees):
    videoMicroglia = []
    
    for v in videoSomas:
        microglia = Microglia(v)
        for f in v.frames:            
            frameSoma  = v.frameSomas[f]
            frameTrees = trees[f]
            
            match = None
            for t in frameTrees:
                if np.all(t.centerNode.coordinates == frameSoma.centroid):
                    match = t
                    break
            
            if match is not None:
                microglia.addTreeAtFrame(match, f)
        
        microglia.matchLeaves()        
        videoMicroglia.append(microglia)
        
    return videoMicroglia


"""
Main method for this file. Translates all skeleton images in a video into
Tree objects, which are directed graphs centered around a soma centroid. Then
it tracks trees across frames and calculates the statistics for each resulting
microglia. 
"""
def process_skeleton(skeleton_fname, img_fname, metadata_fname, soma_fname, microglia_fname):
    skel_tif = TIFF.open(skeleton_fname, mode='r')
    img_tif  = TIFF.open(img_fname, mode='r')
    
    path = os.path.dirname(skeleton_fname)
    metadata_fname = os.path.join(path, metadata_fname)
    soma_fname = os.path.join(path, soma_fname)
    microglia_fname = os.path.join(path, microglia_fname)
    
    with open(soma_fname, 'rb') as f:
        videoSomas = pickle.load(f)

    frame = 0
    directedTrees = {}
    tree_csr_imgs = {}
    
    for skel, img in zip(skel_tif.iter_images(), img_tif.iter_images()): 
        somas = []
        for v in videoSomas:
            if frame in v.frames: somas.append(v.frameSomas[frame])
            
        (trees, tree_csr_img) = skeleton_to_tree(skel, img, somas)
        directedTrees[frame] = trees
        tree_csr_imgs[frame] = tree_csr_img
        frame += 1
        
    skel_tif.close()
    img_tif.close()
    
    output_fname = os.path.join(path, "tree_csrs.tif")
    out_tif = TIFF.open(output_fname, mode='w')
    for img in tree_csr_imgs.values():
        out_tif.write_image(img.astype('<u2'))
    
    #with open(os.path.join(path, 'directedTrees_unpruned.p'), 'wb') as f:
    #    pickle.dump(directedTrees, f)
    
    # Prune short branches
    for frame in directedTrees:
        for dT in directedTrees[frame]:
            dT.prune()
    
    #with open(os.path.join(path, 'directedTrees_pruned.p'), 'wb') as f:
    #    pickle.dump(directedTrees, f)
        
    microglia = match_trees(videoSomas, directedTrees)
        
    with open(microglia_fname, 'wb') as f:
        pickle.dump(microglia, f)

        

if __name__=='__main__':
    img_fname = "/mnt/storage/BaramLabFiles/7-20-17_CRH-tdTomato+CX3CR1-GFP P8 PVN CES/7-20-17_CRH-tdTomato+CX3CR1-GFP P8 PVN CES_Male 3 L PVN T1_b_4D_Male 3 L PVN T1.ims"

    path = os.path.dirname(img_fname)
    path = os.path.join(path, "video_processing", 
                        os.path.basename(img_fname)[0:-4])
    
    img_fname = os.path.join(path, 'preprocessed_max_projection_10iter.tif')
    skeleton_fname = os.path.join(path, 'skeleton.tif')
    metadata_fname = os.path.join(path, 'img_metadata.p')
    soma_fname = os.path.join(path, 'somas.p')
    microglia_fname = os.path.join(path, 'processed_microglia.p')
    tree_fname = os.path.join(path, 'directedTrees_pruned.p')
    
    start_time = timeit.default_timer()
    
    process_skeleton(skeleton_fname, img_fname, metadata_fname, soma_fname, microglia_fname)

    elapsed = timeit.default_timer() - start_time
    print(elapsed)
    
    """
    start_time = timeit.default_timer()
    
    with open(soma_fname, 'rb') as f:
        videoSomas = pickle.load(f)
        
    with open(tree_fname, 'rb') as f:
        directedTrees = pickle.load(f)
        
    microglia = match_trees(videoSomas, directedTrees)
    
    with open(microglia_fname, 'wb') as f:
        pickle.dump(microglia, f)
    
    elapsed = timeit.default_timer() - start_time
    print(elapsed)
    """

